{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사람들 얼굴 인식해서 감정 알아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(path):\n",
    "    \"\"\"Detects faces in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient() # 비전 api 객체 생성\n",
    "\n",
    "    with io.open(path, 'rb') as image_file: # 이미지 불러오기\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content) # 이미지를 vison api에 사용 가능한 객체로 전환\n",
    "\n",
    "    response = client.face_detection(image=image) # 생성한 객체에서 얼굴 인식 수행\n",
    "    faces = response.face_annotations # 얼굴 감지의 결과를 가지고 있는 객체\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Faces:')\n",
    "\n",
    "    for face in faces:\n",
    "        \n",
    "        print('anger: {}'.format(likelihood_name[face.anger_likelihood])) \n",
    "        print('joy: {}'.format(likelihood_name[face.joy_likelihood]))\n",
    "        print('surprise: {}'.format(likelihood_name[face.surprise_likelihood]))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in face.bounding_poly.vertices]) # 객체를 둘러싸는 x와 y 값 반환\n",
    "\n",
    "        print('face bounds: {}'.format(','.join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces:\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (438,101),(485,101),(485,155),(438,155)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (373,144),(424,144),(424,204),(373,204)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (139,90),(182,90),(182,140),(139,140)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: LIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (217,47),(255,47),(255,91),(217,91)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (446,193),(501,193),(501,258),(446,258)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (245,170),(287,170),(287,218),(245,218)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_LIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (43,125),(84,125),(84,171),(43,171)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (498,139),(553,139),(553,202),(498,202)\n",
      "Likelihood.VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "joy: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "face bounds: (70,49),(108,49),(108,92),(70,92)\n"
     ]
    }
   ],
   "source": [
    "detect_faces(\"C:/Users/qud97/Desktop/crawl/AutoCrawler/download/ITRI/google_0012.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사진에 있는 물체들 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localize_objects(path):\n",
    "    \"\"\"Localize objects in the local image.\n",
    "\n",
    "    Args:\n",
    "    path: The path to the local file.\n",
    "    \"\"\"\n",
    "    from google.cloud import vision\n",
    "    import cv2\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    objects = client.object_localization(\n",
    "        image=image).localized_object_annotations # 객체, 객체의 위치, 객체가 포함된 이미지 영역의 사각형 경계에 대한 정보를 식별\n",
    "    \n",
    "    print('Number of objects found: {}'.format(len(objects)))\n",
    "    for object_ in objects:\n",
    "        print('\\n{} (confidence: {})'.format(object_.name, object_.score))\n",
    "        print('Normalized bounding polygon vertices: ')\n",
    "        for vertex in object_.bounding_poly.normalized_vertices: # bounding_poly한 값을 원래 이미지에 대한 비율로 나타냄\n",
    "            print(' - ({}, {})'.format(vertex.x, vertex.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사진을 분석해서 얼굴을 찾아내고, 얼굴에 사각형을 그려 반환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(face_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of Face objects with information about the picture.\n",
    "    \"\"\"\n",
    "    from google.cloud import vision\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    content = face_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    return client.face_detection(\n",
    "        image=image, max_results=max_results).face_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_faces(image, faces, output_filename):\n",
    "    \"\"\"Draws a polygon around the faces, then saves to output_filename.\n",
    "\n",
    "    Args:\n",
    "      image: a file containing the image with the faces.\n",
    "      faces: a list of faces found in the file. This should be in the format\n",
    "          returned by the Vision API.\n",
    "      output_filename: the name of the image file to be created, where the\n",
    "          faces have polygons drawn around them.\n",
    "    \"\"\"\n",
    "    im = Image.open(image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    # Sepecify the font-family and the font-size\n",
    "    for face in faces:\n",
    "        box = [(vertex.x, vertex.y)\n",
    "               for vertex in face.bounding_poly.vertices]\n",
    "        draw.line(box + [box[0]], width=5, fill='#00ff00')\n",
    "        # Place the confidence value/score of the detected faces above the\n",
    "        # detection box in the output image\n",
    "        draw.text(((face.bounding_poly.vertices)[0].x,\n",
    "                   (face.bounding_poly.vertices)[0].y - 30),\n",
    "                  str(format(face.detection_confidence, '.3f')) + '%',\n",
    "                  fill='#FF0000')\n",
    "    im.save(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_filename, output_filename, max_results):\n",
    "    with open(input_filename, 'rb') as image:\n",
    "        faces = detect_face(image, max_results)\n",
    "        print('Found {} face{}'.format(\n",
    "            len(faces), '' if len(faces) == 1 else 's'))\n",
    "\n",
    "        print('Writing to file {}'.format(output_filename))\n",
    "        # Reset the file pointer, so we can read the file again\n",
    "        image.seek(0)\n",
    "        highlight_faces(image, faces, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 faces\n",
      "Writing to file C:/Users/qud97/Desktop/crawl/AutoCrawler/google_0012.jpg\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "from PIL import Image, ImageDraw\n",
    "main(\"C:/Users/qud97/Desktop/crawl/AutoCrawler/download/ITRI/google_0012.jpg\", \n",
    "    \"C:/Users/qud97/Desktop/crawl/AutoCrawler/google_0012.jpg\", 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
