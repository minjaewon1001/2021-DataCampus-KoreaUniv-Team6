# FaceNet: A Unified Embedding for Face Recognition and Clustering
> * CVPR2015
> * 저자: Florian Schroff, Dmitry Kalenichenko, James Philbin
> * url: https://openaccess.thecvf.com/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf


> facenet을 이용하여 얼굴인식을 수행한 다른 논문
> * 아동 얼굴 인식 - https://arxiv.org/pdf/1711.03990v1.pdf 

## Abstract
지금부터 소개할 facenet은 얼굴 이미지로부터 유클리드 공간의 관계를 직접적으로 학습한다. (거리가 얼굴 유사도를 나타내고 가까울수록 유사도가 높음)   
이 방법은 기존 접근 방법의 중간 **Bottleneck Layer**를 사용하는 대신에, 이것을 **임베딩**하는데 최적화되어 있는 **Deep Convolution Network**를 사용하는 방법이며 아주 높은 정확도를 보인다. 

![image](https://user-images.githubusercontent.com/67731178/126897715-84459892-b56c-44ac-8fe3-0f14df39762c.png)

> * 임베딩이란 고차원벡터의 변환을 통해 생성할 수 있는 상대적인 저차원 공간을 말한다. 데이터를 n차원 임베딩을 한다는 것은 그 데이터를 n개의 측면에서 설명할 수 있다는 것이 된다. 이러한 임베딩은 데이터를 통해 학습할 수 있다.   
> * bottleneck layer는 cnn기법에서 중간에 쓰이는 layer로, 출력 데이터의 차원을 줄여서 연산을 효율적으로 하기 위해 쓴다. >< 모양이라서 bottleneck이라고 부른다.   
> * deep convolution network는 cnn에 관한 내용인듯 하다.   
> 
> 임베딩, bottleneck layer와 deep convolution network에 관한 더 자세한 내용은 다른 파일에 정리해놓은 것이 있으니 참고바람.

## 1.	Introduction

facenet의 세가지 통합 시스템은 다음과 같다.
**Face-Verification(동일인물인지), Recognition(누구인지), Clustering(공통되는 사람들 찾기)**
* Face-Verification : 두 임베딩 사이의 거리가 일정 차이를 넘는지
* Recognition: K-NN classification문제
* Clustering: k-means나 agglomerative clustering(병합군집)   
같은 것으로 바로 해결 가능하다.

> * KNN(k-nearest Neighbor)는 어떤 데이터가 주어지면 그 주변의 데이터를 살펴본 뒤 더 많은 데이터가 포함되어 있는 범주로 분류하는 방식이다. 가장 가까운 주변 데이터 k개를 기반으로 분류하기 때문에 k의 값을 어떻게 정하느냐에 따라 결과값이 달라진다. 데이터와 데이터 사이의 거리를 구하는 법으로 유클리드 거리와 맨해튼 거리를 쓴다.
> * k-means clustering은 분리형 군집화 알고리즘으로 각 군집은 하나의 중심(centroid)를 가진다. 각 개체는 가장 가까운 중심에 할당되며, 같은 중심에 할당된 개체들이 모여 하나의 군집을 형성한다. 사용자가 사전에 군집수 k를 정해야 알고리즘을 실행할 수 있다. 처음에 랜덤한 위치로 각 군집의 중심을 초기화하고, 알고리즘을 거치면서 중심이 점점 이동하여 결정이 된다.
> * agglomerative clustering은 시작할 때 각 포인트를 하나의 클러스터로 지정하고, 그 다음 종료 조건을 만족할 때까지 가장 비슷한 두 클러스터를 합치는 알고리즘이다. 종료조건은 클러스터의 갯수로, 지정된 갯수의 클러스터가 남을 때까지 비슷한 클러스터를 합친다.   
> 세 알고리즘 모두 거리 측정을 기반으로 동작하는 알고리즘이다.
> 
> 알고리즘의 더 자세한 과정은 다른 파일에 추후 정리할 예정


이전의 deep net 기반 얼굴인식은 known face identities의 집합으로 학습된 classification layer을 사용하였고 학습에 사용되었던 identities들의 집합을 넘어 얼굴 인식을 일반화하기 위한 방법으로 중간 병목층을 사용했다.   
단점: indirectness와 비효율성 – 새로운 얼굴에 대해서 병목 representation이 잘 일반화해주길 바래야 하며 병목층을 이용하기에 얼굴마다 representation size가 보통 매우 크다.   
최근에는 PCA(고차원의 데이터를 저차원으로 환원해주는 통계학적 기법)를 이용해 이런 차원 문제를 줄였다


![image](https://user-images.githubusercontent.com/67731178/126897721-618a609d-0e3b-42c5-88b2-84100c15011b.png)

Facenet은 **LMNN(Large margin nearest neighbor)** 을 기반으로 **triplet loss**를 이용하여 128차원 임베딩이 아웃풋이 되도록 학습한다.   
triplet은 2개의 일치하는 얼굴과 하나의 다른 얼굴로 이루어져있으며 loss는 distance margin으로 일치하는 쪽을 불일치하는 쪽으로부터 분리해내는데 초점을 두고 있댜.   
더 자세한 내용은 아래에서 설명할 예정이다.   
Thumbnails(썸네일)은 2D, 3D 정렬이 아니고 얼굴 영역에 딱 맞게 잘려 있으며 scale과 translation이 적용되어 있다.
> LMNN(Large margin nearest neighbor)은  Mahalanobis Metric을 직접 학습하는 알고리즘이다.   
> 참고 자료 http://sanghyukchun.github.io/37/ , http://sanghyukchun.github.io/38/

어느 triplets을 사용할지가 성능에 직결되며 Curriculum learning으로 inspired된다.
Clustering의 정확도를 높이기 위해서는 한 사람의 임베딩에 대한 구형의 cluster를 encourage시키는 **hard-positive mining techniques**을 찾아야한다.
> hard positive mining 이란 bounding box를 학습 시킬 때 안에 내가 보고싶어하는 물체가 담긴 샘플(positive example) 중에서 좋은 positive example을 가져오는 방법이다.
> 보통은 negative sample을 정의하는 것이 더 어렵기 때문에 hard negative mining에 관한 기술이 더 많다.

# 2. Related Work
최근 컴퓨터 비전에서 큰 성과를 거둔 두 개의 다른 deep net 구조를 살펴보자. (두 개 다 CNN을 사용했다.)

1. 첫번째 모델은 Zeiler&Fergus Model에 기반을 둔 multiple inter- leaved layers of convolutions, non-linear activations, local response normalizations, and max pooling layers로 이루어져 있다. 우리는 여기에 1x1xd의 conv layer를 추가하였다.

2. 두번째 모델은 Inception model of Szegedy에 기반을 두었으며 최근에 ImageNet에 대해 성공적인 접근을 이루었다.


